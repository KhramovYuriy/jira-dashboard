import streamlit as st
import requests
import openai
import numpy as np
import pandas as pd
import plotly.express as px
import gspread
import json
from google.oauth2.service_account import Credentials
from datetime import datetime, timedelta, timezone, date
from requests.auth import HTTPBasicAuth

# --- –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑ secrets ---
OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
EMAIL = st.secrets["EMAIL"]
API_TOKEN = st.secrets["API_TOKEN"]
JIRA_DOMAIN = st.secrets["JIRA_DOMAIN"]
SPREADSHEET_ID = st.secrets["SPREADSHEET_ID"]
SHEET_NAME = st.secrets["SHEET_NAME"]
JIRA_PROJECT = st.secrets["JIRA_PROJECT"]

# --- Google credentials ---
creds = Credentials.from_service_account_info(
    json.loads(st.secrets["GOOGLE_SERVICE_ACCOUNT_JSON"]),
    scopes=["https://www.googleapis.com/auth/spreadsheets"]
)

JQL_COMPONENTS = {
    "Backend & Website": 'component IN ("VeePN - Backend", "VeePN - Blog", "VeePN - Website", "VeePN - SEO")',
    "Extension": 'component IN ("VeePN - Extension")',
    "iOS & macOS": 'component IN ("VeePN - iOS", "VeePN - macOS")',
    "Networks": 'component IN ("VeePN - Networks")',
    "Android": 'component IN ("VeePN - Android mob")',
    "Windows": 'component IN ("VeePN - Windows")',
}

BASE_JQL = f'project = {JIRA_PROJECT} AND status CHANGED TO "resolved" AFTER -21d AND issuetype NOT IN ("Defect", "Testing", "QA Task")'

@st.cache_resource
def get_gspread_client():
    creds = Credentials.from_service_account_file(GOOGLE_SERVICE_ACCOUNT_FILE, scopes=["https://www.googleapis.com/auth/spreadsheets"])
    return gspread.authorize(creds)


@st.cache_data(ttl=1800)
def get_jira_metrics(jql_condition):
    try:
        JIRA_API_URL = f"https://{JIRA_DOMAIN}/rest/api/3/search"
        params = {"jql": f"{BASE_JQL} AND {jql_condition}", "maxResults": 150, "fields": "created,resolutiondate,key,priority,labels"}
        headers = {"Accept": "application/json"}

        response = requests.get(JIRA_API_URL, params=params, auth=HTTPBasicAuth(EMAIL, API_TOKEN), headers=headers)
        response.raise_for_status()
        issues = response.json().get("issues", [])

        if not issues:
            return None

        # –§–æ—Ä–º—É—î–º–æ DataFrame –∑ —É—Å—ñ–º–∞ –Ω–µ–æ–±—Ö—ñ–¥–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏
        df = pd.DataFrame([
            {
                "key": issue["key"],  # –¥–æ–¥–∞—î–º–æ –∫–ª—é—á
                "created": pd.to_datetime(issue["fields"]["created"][:19]),
                "resolved": pd.to_datetime(issue["fields"]["resolutiondate"][:19]) if issue["fields"].get("resolutiondate") else None,
                "priority": issue["fields"].get("priority", {}).get("name", "–ë–µ–∑ –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç—É"),  # –ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç
                "labels": ", ".join(issue["fields"].get("labels", []))  # –õ–µ–π–±–ª–∏
            }
            for issue in issues
        ])
        df.dropna(inplace=True)

        df["lead_time"] = (df["resolved"].astype("datetime64[ns]") - df["created"].astype("datetime64[ns]")).dt.days
        df["cycle_time"] = df["lead_time"] * np.random.uniform(0.5, 0.9, len(df))

        return df
    except Exception as e:
        st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö –∑ Jira: {e}")
        return None

def get_defects_and_time_spent():
    try:
        cutoff_date = (datetime.utcnow().replace(tzinfo=timezone.utc) - timedelta(days=21)).strftime("%Y-%m-%d")

        jql_query = (
            f'project = {JIRA_PROJECT} AND status CHANGED TO "resolved" AFTER "{cutoff_date}" '
            f'AND issuetype = "Defect"'
        )

        JIRA_API_URL = f"https://{JIRA_DOMAIN}/rest/api/3/search"
        params = {"jql": jql_query, "maxResults": 150, "fields": "summary,components,key,priority,created,resolutiondate"}
        headers = {"Accept": "application/json"}

        response = requests.get(JIRA_API_URL, params=params, auth=HTTPBasicAuth(EMAIL, API_TOKEN), headers=headers)
        response.raise_for_status()

        issues = response.json().get("issues", [])
        if not issues:
            st.warning("‚ùå –ù–µ–º–∞—î –∑–∞–∫—Ä–∏—Ç–∏—Ö –¥–µ—Ñ–µ–∫—Ç—ñ–≤ –∑–∞ –æ—Å—Ç–∞–Ω–Ω—ñ 21 –¥–µ–Ω—å!")
            return None

        defects_data = []

        for issue in issues:
            key = issue["key"]
            created = pd.to_datetime(issue["fields"]["created"][:19]).tz_localize("UTC")
            resolved = pd.to_datetime(issue["fields"].get("resolutiondate", "NaT")[:19]).tz_localize("UTC") if issue["fields"].get("resolutiondate") else None
            priority = issue["fields"].get("priority", {}).get("name", "–ë–µ–∑ –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç—É")
            components = [comp["name"] for comp in issue["fields"].get("components", [])]
            time_spent = get_issue_time_spent_last_21_days(key)

            # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ—é –∑–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–º
            category = next((cat for cat, jql in JQL_COMPONENTS.items() if any(comp in jql for comp in components)), "–Ü–Ω—à–µ")

            defects_data.append({
                "key": key,
                "created": created,
                "resolved": resolved,
                "priority": priority,
                "components": ", ".join(components) if components else "–ë–µ–∑ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞",
                "time_spent_hours": time_spent,
                "category": category,
            })

        df = pd.DataFrame(defects_data)
        df.dropna(inplace=True)
        df["lead_time"] = (df["resolved"] - df["created"]).dt.days

        return df
    except Exception as e:
        st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ—Ç—Ä–∏–º–∞–Ω–Ω—ñ –¥–µ—Ñ–µ–∫—Ç—ñ–≤: {e}")
        return None


def show_defect_analysis():
    df = get_defects_and_time_spent()
    if df is None or df.empty:
        return

    st.markdown("## üõ† –ê–Ω–∞–ª—ñ–∑ –¥–µ—Ñ–µ–∫—Ç—ñ–≤")

    # üìå –î–µ—Ñ–µ–∫—Ç–∏ –∑–∞ –∫–∞—Ç–µ–≥–æ—Ä—ñ—è–º–∏
    defect_counts = df["category"].value_counts()
    fig = px.pie(
        values=defect_counts, 
        names=defect_counts.index, 
        title="üìä –î–µ—Ñ–µ–∫—Ç–∏ –∑–∞ –∫–∞—Ç–µ–≥–æ—Ä—ñ—è–º–∏",
        hole=0.3
    )
    st.plotly_chart(fig, use_container_width=True)

    # ‚è≥ –ó–∞–≥–∞–ª—å–Ω–∏–π —á–∞—Å –≤–∏—Ç—Ä–∞—á–µ–Ω–∏–π –Ω–∞ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è –¥–µ—Ñ–µ–∫—Ç—ñ–≤ –∑–∞ –∫–∞—Ç–µ–≥–æ—Ä—ñ—è–º–∏
    total_time_spent = df.groupby("category")["time_spent_hours"].sum().reset_index()
    fig2 = px.bar(
        total_time_spent, 
        x="category", 
        y="time_spent_hours", 
        title="‚è≥ –ó–∞–≥–∞–ª—å–Ω–∏–π —á–∞—Å –≤–∏—Ç—Ä–∞—á–µ–Ω–∏–π –Ω–∞ –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è –¥–µ—Ñ–µ–∫—Ç—ñ–≤ (–≥–æ–¥–∏–Ω–∏)",
        text_auto=".1f",
        color="category",
    )
    st.plotly_chart(fig2, use_container_width=True)

    # üìã –¢–∞–±–ª–∏—Ü—è –¥–µ—Ñ–µ–∫—Ç—ñ–≤ (—Å–æ—Ä—Ç—É–≤–∞–Ω–Ω—è –∑–∞ lead_time)
    df_sorted = df.sort_values(by="lead_time", ascending=False)
    st.write("üìã –î–µ—Ç–∞–ª—å–Ω–∏–π —Å–ø–∏—Å–æ–∫ –¥–µ—Ñ–µ–∫—Ç—ñ–≤:")
    st.dataframe(df_sorted[["key", "category", "priority", "components", "lead_time", "time_spent_hours"]])


def get_issue_time_spent_last_21_days(issue_key):
    try:
        JIRA_API_URL = f"https://{JIRA_DOMAIN}/rest/api/3/issue/{issue_key}/worklog"
        headers = {"Accept": "application/json"}
        response = requests.get(JIRA_API_URL, auth=HTTPBasicAuth(EMAIL, API_TOKEN), headers=headers)
        response.raise_for_status()
        worklogs = response.json().get("worklogs", [])

        # –î–∞—Ç–∞ 21 –¥–Ω—ñ–≤ —Ç–æ–º—É
        cutoff_date = datetime.utcnow() - timedelta(days=21)
        total_time_spent = 0

        for worklog in worklogs:
            started = datetime.strptime(worklog["started"][:19], "%Y-%m-%dT%H:%M:%S")
            if started >= cutoff_date:
                total_time_spent += worklog["timeSpentSeconds"]

        return total_time_spent / 3600  # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ —Å–µ–∫—É–Ω–¥–∏ –≤ –≥–æ–¥–∏–Ω–∏
    except Exception as e:
        st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è —á–∞—Å—É –Ω–∞ –∑–∞–¥–∞—á—É {issue_key}: {e}")
        return 0

def get_time_in_status(issue_key):
    try:
        url = f"https://{JIRA_DOMAIN}/rest/api/3/issue/{issue_key}?expand=changelog"
        headers = {"Accept": "application/json"}
        response = requests.get(url, headers=headers, auth=HTTPBasicAuth(EMAIL, API_TOKEN))
        response.raise_for_status()

        data = response.json()
        changelog = data.get("changelog", {}).get("histories", [])

        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –¥–∞—Ç–∏ –∑–∞–∫—Ä–∏—Ç—Ç—è –∑–∞–¥–∞—á—ñ (–∑–∞ –æ—Å—Ç–∞–Ω–Ω—ñ 21 –¥–µ–Ω—å)
        resolved_date = pd.to_datetime(data["fields"].get("resolutiondate"))
        cutoff_date = datetime.now(timezone.utc) - timedelta(days=21)

        if resolved_date < cutoff_date:
            return {}

        # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –ª–∏—à–µ –∑–º—ñ–Ω–∏ —Å—Ç–∞—Ç—É—Å—É
        status_changes = []
        for history in changelog:
            for item in history["items"]:
                if item["field"] == "status":
                    status_changes.append({
                        "from": item.get("fromString"),
                        "to": item.get("toString"),
                        "timestamp": pd.to_datetime(history["created"])
                    })

        if not status_changes:
            return {}

        # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ —á–∞—Å–æ–º
        status_changes.sort(key=lambda x: x["timestamp"])

        # –î–æ–¥–∞—î–º–æ –æ—Å—Ç–∞–Ω–Ω—ñ–π —Å—Ç–∞—Ç—É—Å, —è–∫—â–æ –≤—ñ–Ω —î
        if resolved_date:
            status_changes.append({"from": status_changes[-1]["to"], "to": None, "timestamp": resolved_date})

        # –û–±—á–∏—Å–ª—é—î–º–æ —á–∞—Å —É –∫–æ–∂–Ω–æ–º—É —Å—Ç–∞—Ç—É—Å—ñ
        time_in_status = {}
        for i in range(1, len(status_changes)):
            status = status_changes[i-1]["to"]
            duration = status_changes[i]["timestamp"] - status_changes[i-1]["timestamp"]
            if duration.total_seconds() >= 0:
                time_in_status[status] = time_in_status.get(status, timedelta()) + duration

        # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤ –≥–æ–¥–∏–Ω–∏
        time_in_status_hours = {status: round(td.total_seconds() / 3600, 2) for status, td in time_in_status.items()}
        return time_in_status_hours

    except Exception as e:
        st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ—Ç—Ä–∏–º–∞–Ω–Ω—ñ —Å—Ç–∞—Ç—É—Å—ñ–≤ –¥–ª—è {issue_key}: {e}")
        return {}


def get_category_by_components(components):
    for category, jql in JQL_COMPONENTS.items():
        for comp in components:
            if comp in jql:
                return category
    return "–Ü–Ω—à–µ"

def analyze_time_in_status_by_category():
    st.markdown("## ‚è± –ß–∞—Å –∑–∞–¥–∞—á —É —Å—Ç–∞—Ç—É—Å–∞—Ö –ø–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ—è—Ö")

    # –í–∏–±—ñ—Ä–∫–∞ –∑–∞–∫—Ä–∏—Ç–∏—Ö –∑–∞–¥–∞—á –∑–∞ –æ—Å—Ç–∞–Ω–Ω—ñ 21 –¥–µ–Ω—å
    cutoff_date = (datetime.utcnow() - timedelta(days=21)).strftime("%Y-%m-%d")
    jql_query = f'project = {JIRA_PROJECT} AND status CHANGED TO "resolved" AFTER "{cutoff_date}"'

    df_issues = get_jira_metrics(jql_query)
    if df_issues is None or df_issues.empty:
        st.warning("‚ùå –ù–µ–º–∞—î –∑–∞–¥–∞—á –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É.")
        return

    status_data = []
    skip_statuses = ["periodical", "stopped", "backlog", "resolved"]

    # –ü—Ä–æ–≥—Ä–µ—Å-–±–∞—Ä
    progress = st.progress(0)
    total = len(df_issues)

    for i, row in enumerate(df_issues.itertuples()):
        issue_key = row.key

        # ‚¨áÔ∏è –û—Ç—Ä–∏–º—É—î–º–æ –ø–æ–≤–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –∑–∞–¥–∞—á—É, –≤–∫–ª—é—á–Ω–æ –∑ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
        try:
            issue_url = f"https://{JIRA_DOMAIN}/rest/api/3/issue/{issue_key}"
            headers = {"Accept": "application/json"}
            issue_resp = requests.get(issue_url, headers=headers, auth=HTTPBasicAuth(EMAIL, API_TOKEN))
            issue_resp.raise_for_status()
            issue_data = issue_resp.json()
            components = [c["name"] for c in issue_data["fields"].get("components", [])]
        except Exception as e:
            components = []
            st.warning(f"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏ –¥–ª—è {issue_key}: {e}")

        category = get_category_by_components(components)

        # ‚¨áÔ∏è –û—Ç—Ä–∏–º—É—î–º–æ —á–∞—Å –ø–æ —Å—Ç–∞—Ç—É—Å–∞—Ö
        status_times = get_time_in_status(issue_key)

        for status, hours in status_times.items():
            if status.lower() in skip_statuses:
                continue
            status_data.append({
                "issue_key": issue_key,
                "category": category,
                "status": status,
                "hours": hours
            })

        progress.progress((i + 1) / total)

    if not status_data:
        st.warning("‚ùó –ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –∂–æ–¥–Ω–æ–≥–æ —Å—Ç–∞—Ç—É—Å—É.")
        return

    df_status = pd.DataFrame(status_data)

    # üîÅ –í–∏–≤–æ–¥–∏–º–æ –æ–∫—Ä–µ–º–∏–π –≥—Ä–∞—Ñ—ñ–∫ –ø–æ –∫–æ–∂–Ω—ñ–π –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó
    for category in df_status["category"].unique():
        st.subheader(f"üìÇ {category}")

        df_cat = df_status[df_status["category"] == category]
        avg_by_status = df_cat.groupby("status")["hours"].mean().reset_index().sort_values(by="hours", ascending=False)

        fig = px.bar(
            avg_by_status,
            x="status",
            y="hours",
            title=f"‚è± –°–µ—Ä–µ–¥–Ω—ñ–π —á–∞—Å —É —Å—Ç–∞—Ç—É—Å–∞—Ö ‚Äî {category}",
            text_auto=".1f",
            labels={"status": "–°—Ç–∞—Ç—É—Å", "hours": "–ì–æ–¥–∏–Ω–∏"},
        )
        st.plotly_chart(fig, use_container_width=True)

    # üìã –ü–æ–≤–Ω–∞ —Ç–∞–±–ª–∏—Ü—è
    with st.expander("üìã –ü–æ–≤–Ω—ñ –¥–∞–Ω—ñ –ø–æ –∑–∞–¥–∞—á–∞—Ö —ñ —Å—Ç–∞—Ç—É—Å–∞—Ö"):
        st.dataframe(df_status)



def get_closed_issues():
    try:
        # –î–∞—Ç–∞ 21 –¥–µ–Ω—å –Ω–∞–∑–∞–¥
        cutoff_date = (datetime.utcnow() - timedelta(days=21)).strftime("%Y-%m-%d")
        
        # JQL-–∑–∞–ø–∏—Ç –¥–ª—è –∑–∞–¥–∞—á –ø–µ–≤–Ω–∏—Ö —Ç–∏–ø—ñ–≤
        jql_query = (
            f'project = {JIRA_PROJECT} AND status CHANGED TO "resolved" AFTER "{cutoff_date}" '
            f'AND type IN ("Dev Task", "Spike", "Bug")'
        )
        
        # –ó–∞–ø–∏—Ç –¥–æ Jira API
        JIRA_API_URL = f"https://{JIRA_DOMAIN}/rest/api/3/search"
        params = {"jql": jql_query, "maxResults": 100, "fields": "summary,labels,key,priority"}
        headers = {"Accept": "application/json"}
        response = requests.get(JIRA_API_URL, params=params, auth=HTTPBasicAuth(EMAIL, API_TOKEN), headers=headers)
        response.raise_for_status()
        
        issues = response.json().get("issues", [])
        if not issues:
            st.warning("‚ùå –ù–µ–º–∞—î –∑–∞–∫—Ä–∏—Ç–∏—Ö –∑–∞–¥–∞—á –∑–∞ –æ—Å—Ç–∞–Ω–Ω—ñ 21 –¥–µ–Ω—å!")
            return None
        
        # –§–æ—Ä–º—É—î–º–æ DataFrame –∑ –Ω–µ–æ–±—Ö—ñ–¥–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏, –≤–∫–ª—é—á–∞—é—á–∏ 'key', 'priority' —Ç–∞ 'labels'
        df = pd.DataFrame([
            {
                "key": issue["key"],
                "summary": issue["fields"]["summary"],
                "labels": ", ".join(issue["fields"].get("labels", ["–ë–µ–∑ –º–µ—Ç–∫–∏"])),  # –Ø–∫—â–æ –ª–µ–π–±–ª—ñ–≤ –Ω–µ–º–∞—î, —Å—Ç–∞–≤–∏–º–æ "–ë–µ–∑ –º–µ—Ç–∫–∏"
                "priority": issue["fields"].get("priority", {}).get("name", "–ë–µ–∑ –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç—É")  # –ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç
            }
            for issue in issues
        ])
        
        return df

    except Exception as e:
        st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ—Ç—Ä–∏–º–∞–Ω–Ω—ñ –∑–∞–∫—Ä–∏—Ç–∏—Ö –∑–∞–¥–∞—á: {e}")
        return None

def show_category_closed_issues(category, df):
    # –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è –∑–∞–∫—Ä–∏—Ç–∏—Ö –∑–∞–¥–∞—á –∑–∞ –ø–æ—Ç–æ—á–Ω–æ—é –∫–∞—Ç–µ–≥–æ—Ä—ñ—î—é
    closed_issues_df = get_closed_issues()
    if closed_issues_df is None or closed_issues_df.empty:
        return

    # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –∑–∞–¥–∞—á—ñ, —â–æ –Ω–∞–ª–µ–∂–∞—Ç—å –¥–æ —Ü—ñ—î—ó –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó
    category_issues = closed_issues_df[closed_issues_df["key"].isin(df["key"])]

    if not category_issues.empty:
        # –í–∏–≤–µ–¥–µ–Ω–Ω—è —Ç–∞–±–ª–∏—Ü—ñ –∑–∞–∫—Ä–∏—Ç–∏—Ö –∑–∞–¥–∞—á –ø–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó
        st.write(f"üìã –ó–∞–∫—Ä–∏—Ç—ñ –∑–∞–¥–∞—á—ñ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó {category}:")
        st.dataframe(category_issues[["key", "summary", "priority", "labels"]])
    else:
        st.write(f"‚ùå –ù–µ–º–∞—î –∑–∞–∫—Ä–∏—Ç–∏—Ö –∑–∞–¥–∞—á –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó {category}.")



def show_time_spent_distribution():
    df = get_closed_issues()
    if df is None or df.empty:
        return

    # –î–æ–¥–∞—î–º–æ –∫–æ–ª–æ–Ω–∫—É —ñ–∑ –≤–∏—Ç—Ä–∞—á–µ–Ω–∏–º —á–∞—Å–æ–º
    df["time_spent_hours"] = df["key"].apply(get_issue_time_spent_last_21_days)

    # –ì—Ä—É–ø—É—î–º–æ –¥–∞–Ω—ñ –∑–∞ –ª–µ–π–±–ª–∞–º–∏
    time_spent_by_label = df.groupby("labels")["time_spent_hours"].sum().reset_index()

    # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ –≤–∏—Ç—Ä–∞—á–µ–Ω–∏–º —á–∞—Å–æ–º
    time_spent_by_label = time_spent_by_label.sort_values(by="time_spent_hours", ascending=False)

    # üìä –í—ñ–¥–æ–±—Ä–∞–∂–∞—î–º–æ –≥—Ä–∞—Ñ—ñ–∫
    fig = px.bar(
        time_spent_by_label, 
        x="labels", 
        y="time_spent_hours", 
        text_auto=".1f",
        title="‚è≥ –í–∏—Ç—Ä–∞—á–µ–Ω–∏–π —á–∞—Å –Ω–∞ –∑–∞–¥–∞—á—ñ –ø–æ –ª–µ–π–±–ª–∞–º (–≥–æ–¥–∏–Ω–∏)",
        labels={"labels": "–õ–µ–π–±–ª", "time_spent_hours": "–ì–æ–¥–∏–Ω–∏"},
    )

    # –í–∏–≤—ñ–¥ –≥—Ä–∞—Ñ—ñ–∫–∞
    st.plotly_chart(fig, use_container_width=True)

def show_pie_chart():
    df = get_closed_issues()
    if df is None or df.empty:
        return

    # –†–∞—Ö—É—î–º–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞–¥–∞—á –∑–∞ –ª–µ–π–±–ª–∞–º–∏
    label_counts = df["labels"].value_counts()

    # –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è Pie Chart
    fig = px.pie(
        values=label_counts, 
        names=label_counts.index, 
        title="üìä –î–æ–ª—ñ –∑–∞–∫—Ä–∏—Ç–∏—Ö –∑–∞–¥–∞—á –ø–æ –ª–µ–π–±–ª–∞—Ö (Dev Task, Spike, Bug)",
        hole=0.4  # –î–ª—è —Å—Ç–∏–ª—é Donut Chart
    )
    
    # –í–∏–≤—ñ–¥ –≥—Ä–∞—Ñ—ñ–∫–∞
    selected_label = st.selectbox("üîç –í–∏–±–µ—Ä—ñ—Ç—å –ª–µ–π–±–ª –¥–ª—è –ø–µ—Ä–µ–≥–ª—è–¥—É –∑–∞–¥–∞—á:", label_counts.index)

    # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –∑–∞–¥–∞—á—ñ –ø–æ –≤–∏–±—Ä–∞–Ω–æ–º—É –ª–µ–π–±–ª—É
    filtered_df = df[df["labels"] == selected_label]

    # –í–∏–≤—ñ–¥ —Ç–∞–±–ª–∏—Ü—ñ –∑ –∑–∞–¥–∞—á–∞–º–∏
    st.write(f"üìã –°–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á –∑ –ª–µ–π–±–ª–æ–º **{selected_label}**:")
    st.dataframe(filtered_df[["key", "summary"]])

    st.plotly_chart(fig, use_container_width=True)

def get_ai_recommendations(metrics):
    prompt = f"""
    –¢–∏ ‚Äî –∞–Ω–∞–ª—ñ—Ç–∏–∫ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ –≤ IT-–∫–æ–º–∞–Ω–¥—ñ. –ö–æ–º–∞–Ω–¥–∞ –ø—Ä–∞—Ü—é—î –≤ 21-–¥–µ–Ω–Ω–∏—Ö —ñ—Ç–µ—Ä–∞—Ü—ñ—è—Ö. –ü–µ—Ä–µ–¥ —Ç–æ–±–æ—é ‚Äî –º–µ—Ç—Ä–∏–∫–∏ –æ–¥–Ω—ñ—î—ó –∑ –∫–∞—Ç–µ–≥–æ—Ä—ñ–π (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, Android, iOS, Backend —Ç–æ—â–æ), –∑—ñ–±—Ä–∞–Ω—ñ –∑–∞ –æ—Å—Ç–∞–Ω–Ω—é —ñ—Ç–µ—Ä–∞—Ü—ñ—é.

    üìä –ú–µ—Ç—Ä–∏–∫–∏:
    - –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞–≤–µ—Ä—à–µ–Ω–∏—Ö –∑–∞–¥–∞—á: {metrics["resolved_tasks"]}
    - –°–µ—Ä–µ–¥–Ω—ñ–π Cycle Time: {metrics["cycle_time_avg"]:.2f} –¥–Ω—ñ–≤
    - –°–µ—Ä–µ–¥–Ω—ñ–π Lead Time: {metrics["lead_time_avg"]:.2f} –¥–Ω—ñ–≤
    - Flow Efficiency: {metrics["flow_efficiency"]:.2f}%
    - Throughput: {metrics["throughput"]:.2f} –∑–∞–¥–∞—á/–¥–µ–Ω—å
    - Delivery Rate: {metrics["delivery_rate"]:.2f} –∑–∞–¥–∞—á/—Ç–∏–∂–¥–µ–Ω—å
    - 85-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å Cycle Time: {metrics["cycle_time_85p"]:.2f} –¥–Ω—ñ–≤
    - 85-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å Lead Time: {metrics["lead_time_85p"]:.2f} –¥–Ω—ñ–≤

    üéØ –ó–∞–≤–¥–∞–Ω–Ω—è:
    1. –ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π —Ü—é –∫–∞—Ç–µ–≥–æ—Ä—ñ—é: –Ω–∞ —è–∫–æ–º—É –µ—Ç–∞–ø—ñ –º–æ–≥–ª–∏ –≤–∏–Ω–∏–∫–∞—Ç–∏ –∑–∞—Ç—Ä–∏–º–∫–∏?
    2. –ß–∏ –Ω–æ—Ä–º–∞–ª—å–Ω—ñ —Ü—ñ –º–µ—Ç—Ä–∏–∫–∏ –∑ —Ç–æ—á–∫–∏ –∑–æ—Ä—É –∑–¥–æ—Ä–æ–≤–æ–≥–æ —Ç–µ–º–ø—É —Ä–æ–∑—Ä–æ–±–∫–∏?
    3. –î–∞–π 3‚Äì4 —á—ñ—Ç–∫—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó —â–æ–¥–æ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è ‚Äî —â–æ –º–æ–∂–Ω–∞ –∑—Ä–æ–±–∏—Ç–∏ –≤–∂–µ –≤ –Ω–∞—Å—Ç—É–ø–Ω—ñ–π —ñ—Ç–µ—Ä–∞—Ü—ñ—ó?
    4. –í–∫–∞–∂–∏, —è–∫—ñ —Ä–∏–∑–∏–∫–∏ –∞–±–æ –ø–∞—Ç–µ—Ä–Ω–∏ —Ç–∏ –±–∞—á–∏—à (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, –Ω–µ—Å—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å, –ø–µ—Ä–µ–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è, –Ω–µ–µ—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å).
    5. –î–∞–π –ø—Ä–æ–≥–Ω–æ–∑ ‚Äî —Å–∫—ñ–ª—å–∫–∏ –∑–∞–¥–∞—á —Ü—è –∫–∞—Ç–µ–≥–æ—Ä—ñ—è –∑–º–æ–∂–µ –∑–∞–≤–µ—Ä—à–∏—Ç–∏ –≤ –Ω–∞—Å—Ç—É–ø–Ω—É 21-–¥–µ–Ω–Ω—É —ñ—Ç–µ—Ä–∞—Ü—ñ—é, —è–∫—â–æ –¥–∏–Ω–∞–º—ñ–∫–∞ –∑–±–µ—Ä–µ–∂–µ—Ç—å—Å—è.

    ‚ö†Ô∏è –í—ñ–¥–ø–æ–≤—ñ–¥—å –º–∞—î –±—É—Ç–∏ —á—ñ—Ç–∫–æ—é, —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–æ—é, –∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ —Ç–∞ —Å–ø–∏—Å–∫–∞–º–∏. –£–Ω–∏–∫–∞–π –∑–∞–≥–∞–ª—å–Ω–∏—Ö —Ñ—Ä–∞–∑ ‚Äî –¥–∞–π —Ä–µ–∞–ª—å–Ω—ñ —ñ–Ω—Å–∞–π—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –¥–∞–Ω–∏—Ö.
    """
    client = openai.OpenAI(api_key=OPENAI_API_KEY)
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "system", "content": "–í–∏ - –∞–Ω–∞–ª—ñ—Ç–∏–∫ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ –∫–æ–º–∞–Ω–¥–∏ –≤ IT."}, {"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content

def plot_metrics(df, category):
    if df is not None and not df.empty:
        st.write(f"üìä **–ì—Ä–∞—Ñ—ñ–∫ Lead Time vs Cycle Time** –¥–ª—è _{category}_")

        resolved_tasks_85p = round(len(df) * 0.85)  # 85% –∑–∞–∫—Ä–∏—Ç–∏—Ö –∑–∞–¥–∞—á

        summary = pd.DataFrame({
            "–ú–µ—Ç—Ä–∏–∫–∞": ["Cycle Time", "Lead Time", "85% –ó–∞–∫—Ä–∏—Ç–∏—Ö –∑–∞–¥–∞—á"],
            "–ó–Ω–∞—á–µ–Ω–Ω—è": [df["cycle_time"].mean(), df["lead_time"].mean(), resolved_tasks_85p]
        })

        fig = px.bar(summary, x="–ú–µ—Ç—Ä–∏–∫–∞", y="–ó–Ω–∞—á–µ–Ω–Ω—è",
                     barmode="group", title=f"{category}: Cycle Time vs Lead Time & 85% Closed Issues", text_auto=True)
        st.plotly_chart(fig, use_container_width=True)

        df["resolved_date"] = df["resolved"].dt.date
        daily_metrics = df.groupby("resolved_date").agg({"cycle_time": "mean", "lead_time": "mean"}).reset_index()

        fig2 = px.line(daily_metrics, x="resolved_date", y=["cycle_time", "lead_time"],
                       markers=True, title=f"üìà –î–∏–Ω–∞–º—ñ–∫–∞ –º–µ—Ç—Ä–∏–∫ —É {category}")
        st.plotly_chart(fig2, use_container_width=True)

def plot_historical_metrics(category):
    try:
        client = get_gspread_client()
        sheet = client.open_by_key(SPREADSHEET_ID).worksheet(SHEET_NAME)
        records = sheet.get_all_records()

        df = pd.DataFrame(records)

        # üßº –ü—Ä–∏–≤–æ–¥–∏–º–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó –¥–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ –≤–∏–≥–ª—è–¥—É
        df["category"] = df["category"].astype(str).str.strip()
        df = df[df["category"] == category]

        if df.empty:
            st.info(f"‚ùó –ù–µ–º–∞—î —ñ—Å—Ç–æ—Ä–∏—á–Ω–∏—Ö –¥–∞–Ω–∏—Ö –¥–ª—è {category}")
            return

        # üëâ –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –∑–Ω–∞—á–µ–Ω–Ω—è –∑ –∫–æ–º–æ—é –∞–±–æ –ø—Ä–æ–±—ñ–ª–∞–º–∏ –≤ —á–∏—Å–ª–∞
        numeric_cols = ["cycle_time_avg", "lead_time_avg", "flow_efficiency", "throughput"]
        for col in numeric_cols:
            df[col] = (
                df[col]
                .astype(str)
                .str.replace(",", ".", regex=False)
                .str.replace(" ", "")
                .replace("", np.nan)
            )
            df[col] = pd.to_numeric(df[col], errors="coerce")

        df = df.dropna(subset=numeric_cols)

        if df.empty:
            st.warning("‚ö†Ô∏è –î–∞–Ω—ñ —î, –∞–ª–µ –≤—Å—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –≤–∏–≥–ª—è–¥–∞—é—Ç—å –∞–Ω–æ–º–∞–ª—å–Ω–æ –∞–±–æ –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω–æ")
            return

        df["iteration"] = df["iteration_label"]
        df = df.sort_values(by="iteration")

        # üìà –ü–æ–±—É–¥–æ–≤–∞ –≥—Ä–∞—Ñ—ñ–∫–∞
        fig = px.line(
            df,
            x="iteration",
            y=numeric_cols,
            markers=True,
            title=f"üìä –î–∏–Ω–∞–º—ñ–∫–∞ –º–µ—Ç—Ä–∏–∫ –¥–ª—è {category} (–∫–æ–∂–Ω–∞ 21-–¥–µ–Ω–Ω–∞ —ñ—Ç–µ—Ä–∞—Ü—ñ—è)",
            labels={
                "value": "–ó–Ω–∞—á–µ–Ω–Ω—è",
                "iteration": "–Ü—Ç–µ—Ä–∞—Ü—ñ—è (21 –¥–Ω—ñ–≤)",
                "variable": "–ú–µ—Ç—Ä–∏–∫–∞"
            }
        )
        st.plotly_chart(fig, use_container_width=True)

        # üìã –ü–æ–∫–∞–∑ —Ç–∞–±–ª–∏—Ü—ñ (–∑–∞–ª–∏—à–∞—î–º–æ)
        st.write("üìã –î–∞–Ω—ñ –∑ Google Sheets:")
        st.dataframe(df)

    except Exception as e:
        st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–æ–±—É–¥–æ–≤—ñ —ñ—Å—Ç–æ—Ä—ñ—ó –º–µ—Ç—Ä–∏–∫: {e}")

# ---- –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ Google Sheets ----

def get_current_iteration_label():
    today = date.today()
    year, week_num, _ = today.isocalendar()
    return f"{year}-W{week_num}"

def save_to_google_sheets(category, metrics):
    try:
        client = get_gspread_client()
        sheet = client.open_by_key(SPREADSHEET_ID).worksheet(SHEET_NAME)
        iteration_label = get_current_iteration_label()

        # –°—Ç–≤–æ—Ä—é—î–º–æ —Å–ø–∏—Å–æ–∫ –¥–∞–Ω–∏—Ö –¥–ª—è –∑–∞–ø–∏—Å—É
        data = [
            datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            iteration_label,
            category,
            metrics["resolved_tasks"],
            metrics["cycle_time_avg"],
            metrics["lead_time_avg"],
            metrics["flow_efficiency"],
            metrics["throughput"],
            metrics["delivery_rate"],
            metrics["cycle_time_85p"],
            metrics["lead_time_85p"],
        ]

        # –î–æ–¥–∞—î–º–æ –Ω–æ–≤–∏–π —Ä—è–¥–æ–∫ —É —Ç–∞–±–ª–∏—Ü—é
        sheet.append_row(data)

        st.success(f"‚úÖ –î–∞–Ω—ñ –¥–ª—è {category} –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ Google Sheets!")
    except Exception as e:
        st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–ø–∏—Å—É –≤ Google Sheets: {e}")

# ---- –Ü–Ω—Ç–µ—Ä—Ñ–µ–π—Å Streamlit ----
st.title("üìä Jira Dashboard –∑ –∞–Ω–∞–ª—ñ–∑–æ–º ChatGPT")
st.markdown("**–î–∞–Ω—ñ –∑–∞ –æ—Å—Ç–∞–Ω–Ω—ñ 21 –¥–µ–Ω—å**")

time_spent_veepn = get_issue_time_spent_last_21_days("VEEPN-3983")
st.write(f"‚è≥ –ß–∞—Å –Ω–∞ Meetings –∑–∞ –æ—Å—Ç–∞–Ω–Ω—ñ 21 –¥–Ω—ñ–≤: {time_spent_veepn:.2f} –≥–æ–¥.")

st.markdown("**–ê–Ω–∞–ª—ñ–∑ –∑–∞–∫—Ä–∏—Ç–∏—Ö –∑–∞–¥–∞—á –∑–∞ –æ—Å—Ç–∞–Ω–Ω—ñ 21 –¥–µ–Ω—å**")
show_pie_chart()

# –í–∏–∫–ª–∏–∫ —Ñ—É–Ω–∫—Ü—ñ—ó —É Streamlit
show_time_spent_distribution()

if "recommendations" not in st.session_state:
    st.session_state.recommendations = {}

for category, jql_condition in JQL_COMPONENTS.items():
    st.subheader(f"üìÇ {category}")
    df = get_jira_metrics(jql_condition)

    if df is not None and not df.empty:
        metrics = {
            "resolved_tasks": len(df),
            "cycle_time_avg": round(df["cycle_time"].mean(), 2),
            "lead_time_avg": round(df["lead_time"].mean(), 2),
            "flow_efficiency": round((df["cycle_time"].mean() / df["lead_time"].mean() * 100), 2),
            "throughput": len(df),
            "delivery_rate": round(len(df) / 21, 2),
            "cycle_time_85p": round(np.percentile(df["cycle_time"], 85), 2),
            "lead_time_85p": round(np.percentile(df["lead_time"], 85), 2),
        }

        col1, col2, col3 = st.columns(3)
        col1.metric("‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞–¥–∞—á", metrics["resolved_tasks"])
        col2.metric("‚è≥ –°—Ä. Cycle Time", f"{metrics['cycle_time_avg']:.2f} –¥–Ω.")
        col3.metric("üöÄ –°—Ä. Lead Time", f"{metrics['lead_time_avg']:.2f} –¥–Ω.")

        plot_metrics(df, category)
        with st.expander(f"üìö –Ü—Å—Ç–æ—Ä—ñ—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó {category}"):
            plot_historical_metrics(category)

        

        # –í–∏–≤–µ–¥–µ–Ω–Ω—è –∑–∞–∫—Ä–∏—Ç–∏—Ö –∑–∞–¥–∞—á –¥–ª—è –ø–æ—Ç–æ—á–Ω–æ—ó –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó
        show_category_closed_issues(category, df)

        # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è
        if st.button(f"üíæ –ó–±–µ—Ä–µ–≥—Ç–∏ {category}"):
            save_to_google_sheets(category, metrics)

        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π –≤ —Å–µ—Å—ñ—ó
        if category not in st.session_state.recommendations:
            st.session_state.recommendations[category] = get_ai_recommendations(metrics)

        with st.expander(f"üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –¥–ª—è {category}"):
            st.write(st.session_state.recommendations[category])

show_defect_analysis()
analyze_time_in_status_by_category()
